---
title: "Magnolia instance is down"
url: https://docs.magnolia-cms.com/paas/troubleshooting/alerts/CustomerMagnoliaDown/
category: DX Cloud
version: cloud
breadcrumb: DX Cloud > Troubleshoot > Magnolia instance is down
---

# Magnolia instance is down

This topic guides you on troubleshooting Magnolia instances that are down.

## [](#_symptom)Symptom

A `CustomerMagnoliaDown` alert is firing.

> **Note:** CustomerMagnoliaDown alerts are sent to subscribers via email.

## [](#_observations)Observations

Here are the details on the alert:

### [](#_alert_customermagnoliadown)Alert: `CustomerMagnoliaDown`

<div class="joplin-table-wrapper"><table class="tableblock frame-all grid-all stretch"><colgroup><col style="width: 30%;"> <col style="width: 70%;"></colgroup><tbody><tr><td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Expression</strong></p></td><td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph"><p><code>up{tier="app"} != 1</code></p></div></div></td></tr><tr><td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Delay</strong></p></td><td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph"><p><code>30</code> minutes</p></div></div></td></tr><tr><td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Labels</strong></p></td><td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph"><p><code>team: customer</code></p></div></div></td></tr><tr><td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Annotations</strong></p></td><td class="tableblock halign-left valign-top"><div class="content"><div class="ulist"><ul><li><p><code>summary</code></p></li><li><p><code>description</code></p></li><li><p><code>tenant</code></p></li><li><p><code>cluster_id</code></p></li><li><p><code>cluster_name</code></p></li><li><p><code>pod</code></p></li><li><p><code>instance</code></p></li><li><p><code>namespace</code></p></li></ul></div></div></td></tr></tbody></table></div>

> **Important:** The alert metric is based on the "up" metric. The "up" metric is generated by Prometheus and means that Prometheus was able to successfully contact the Magnolia instance and collect metrics from it.

There are a number of reasons that Prometheus can fail to collect metrics from a Magnolia instance:

-   The Magnolia instance is not running.

-   The metrics collection job for the Magnolia instance is misconfigured.

-   The Magnolia instance does not respond to the metrics request within the scrape timeout.

-   The Magnolia instance is not responding to requests.

-   The metrics endpoint (`/<app context>/.monitoring/scrape`) is not accessible to Prometheus.


### [](#_check_magnolia_is_running)Check Magnolia is running

The alert will note the affected Magnolia pod. You can check if Kubernetes considers the Magnolia instance is running in Rancher or with `kubectl`.

-   Rancher

-   `kubectl`


Check the status of the pod directly in the Rancher UI.

With `kubectl`, check the Magnolia pod:

```none
kubectl -n <NAMESPACE_IN_ALERT> describe pod <MAGNOLIA_POD> (1)
```

|     |     |
| --- | --- |
| **1** | Replace the variables here. |

### [](#_check_magnolia_metrics_collection_job_configuration)Check Magnolia metrics collection job configuration

Metrics are collected from the Magnolia pod by a Prometheus instance running on the local cluster. You can check the status of the metrics collection job by connecting to the local Prometheus instance.

1.  Connect to Prometheus.

    ```bash
    kubectl -n monitoring port-forward pod/prometheus-monitoring-kube-prometheus-prometheus-0 9090 (1)
    ```

    |     |     |
    | --- | --- |
    | **1** | Connect to the Prometheus instance with a browser at `http://localhost:9090`. |

2.  Click on the "Status" menu and select "Targets".

    *You should now see the status of all metrics collection jobs on the local Prometheus instance.*

    ![prometheus targets](../../../_images/troubleshooting/alerts/prometheus_targets.png)

3.  Click on "show more" of the metrics collection job of the desired Magnolia instance:

    ![prometheus failing target](../../../_images/troubleshooting/alerts/prometheus_failing_target.png)

    > **Note:** Note the endpoint, the scrape time (Last Scrape), and the error reported by Prometheus.


### [](#_action_check_that_the_metrics_endpoint_is_accessible)Action: Check that the metrics endpoint is accessible

1.  Connect to the Magnolia instance with port forwarding:

    ```bash
    kubectl -n <namespace from alert> port-forward pod/<Magnolia pod from alert> 8080 (1)
    ```

    |     |     |
    | --- | --- |
    | **1** | This should allow you to access [http://localhost:8080/.metrics/scrape](http://localhost:8080/.metrics/scrape). |


> **Note:** You may need to add an application context (e.g. /author/.metrics/scrape) if Magnolia has been deployed with a context.

Magnolia should return metrics like this:

```text
# HELP jvm_memory_bytes_used Used bytes of a given JVM memory area.
# TYPE jvm_memory_bytes_used gauge
jvm_memory_bytes_used{area="heap",} 3.851850344E9
jvm_memory_bytes_used{area="nonheap",} 2.906232E8
# HELP jvm_memory_bytes_committed Committed (bytes) of a given JVM memory area.
# TYPE jvm_memory_bytes_committed gauge
jvm_memory_bytes_committed{area="heap",} 7.732199424E9
jvm_memory_bytes_committed{area="nonheap",} 3.05815552E8
# HELP jvm_memory_bytes_max Max (bytes) of a given JVM memory area.
# TYPE jvm_memory_bytes_max gauge
jvm_memory_bytes_max{area="heap",} 7.732199424E9
jvm_memory_bytes_max{area="nonheap",} -1.0
# HELP jvm_memory_bytes_init Initial bytes of a given JVM memory area.
# TYPE jvm_memory_bytes_init gauge
jvm_memory_bytes_init{area="heap",} 2.01326592E8
jvm_memory_bytes_init{area="nonheap",} 7667712.0
...
```

## [](#_solutions)Solutions

This section provides solutions that should help resolve the issue in most cases.

### [](#_prometheus_reports_404_when_collecting_metrics)Prometheus reports `404` when collecting metrics

If Magnolia is up and running but the Prometheus metrics collection returns a `404`, you can change the metrics scrape path.

Change the scrape path by adding an annotation to the service using the Magnolia instance:

```bash
kubectl -n <namespace> annotate service <deployment>-magnolia-helm-author-svc "magnolia.info/context-path"="/<app context>/.monitoring/scrape" --overwrite
```

> **Note:** The application context for author instances is usually "author", so the path should be "/author/.monitoring/scrape".Prometheus will detect the new path from the service annotation, reload its configuration and collecting metrics from Magnolia. This can take a 1 - 3 minutes.Connect to the local Prometheus instance as described above using port forwarding and check the status of the scrape jobs.

### [](#_prometheus_reports_403_when_collecting_metrics)Prometheus reports `403` when collecting metrics

This means you cannot access metrics endpoint with port forwarding. The configuration of the metrics endpoint included in the instrumentation module should allow anonymous access to the endpoint.

1.  In AdminCentral, go to the Security app.

2.  Go to the Roles tab within the app.

3.  Select the anonymous role from the list.

    1.  With **anonymous** selected, click Edit role.

    2.  Go to the Web Access tab

    3.  Ensure the role is allowed to `Get` and `Post` to `/.monitoring/*`.



### [](#_prometheus_reports_a_timeout_when_collecting_metrics)Prometheus reports a timeout when collecting metrics

If Magnolia does not respond with metrics within `10` seconds, the metrics collection job will fail. Metrics collection must fail for `30` minutes (`30` consecutive failures) for this alert to be triggered.

Unlikely scenario

This case is unlikely; failing to collect metrics for `30` minutes because of timeout shows Magnolia is highly loaded.

Other alerts, such as [Magnolia author or public slow response](../CustomerMagnoliaSlowResponse/) or [Tomcat is showing high load or slow requests](../CustomerTomcatHighLoad/), will likely fire.

### [](#_kubernetes_reports_magnolia_is_not_running)Kubernetes reports Magnolia is not running

Check Rancher or `kubectl` for the status of the Magnolia instance for indications why the Magnolia is failing to start.
